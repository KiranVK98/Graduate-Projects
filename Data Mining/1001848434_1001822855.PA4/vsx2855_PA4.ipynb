{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment # 4 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When submitting, fill your full name, your student ID and your NetID in this cell. Note that this is a markdown cell! \n",
    "\n",
    "Student Full Name: Vijetha Shenoy B\n",
    "\n",
    "ID:1001822855\n",
    "\n",
    "Team Mate name :\n",
    "\n",
    "ID: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Work is to be done in a team\n",
    "2. Any cheating including plagiarism, cooperation will be reported to the corresponding UTA’ s instance.\n",
    "3. If using any resource (books, internet), please make sure that you cite it.\n",
    "4. Follow the given structure. Specifically, place all your tasks in THIS NOTEBOOK BUT IN SEPARATE BLOCKS. Then save this notebook as 'yourNetID_pa3.ipynb' and submit it. \n",
    "5. Do not alter the dataset name.\n",
    "6. Please dont ask any details specific to the project like \"How to plot XYZ ? What parameters are to be used? \" and so on..\n",
    "7. Report is not required for this assignment. If you want to document a function or a process, just comment or use markup cell.\n",
    "8. Please dont send images of your visualizations to verify whether they are right or not before submission deadline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The purpose of this assignment is to cluster  using K-means clustering and Hierarchical Agglomerative clustering models and to visualize clusters for predicted and actual cluster labels.\n",
    "\n",
    "\n",
    "Your dataset is given as 3 files . \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You need to submit this ipython file after renaming it. \n",
    "\n",
    "Preprocessing will be needed for the data as most of the data is in string and needs to be quantified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Python Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import *\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>Fnlwght</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNumber</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age          WorkClass  Fnlwght   Education  EducationNumber  \\\n",
       "0   39          State-gov    77516   Bachelors               13   \n",
       "1   50   Self-emp-not-inc    83311   Bachelors               13   \n",
       "2   38            Private   215646     HS-grad                9   \n",
       "3   53            Private   234721        11th                7   \n",
       "4   28            Private   338409   Bachelors               13   \n",
       "\n",
       "         MaritalStatus          Occupation    Relationship    Race      Sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   CapitalGain  CapitalLoss  HoursPerWeek   NativeCountry   Class  \n",
       "0         2174            0            40   United-States   <=50K  \n",
       "1            0            0            13   United-States   <=50K  \n",
       "2            0            0            40   United-States   <=50K  \n",
       "3            0            0            40   United-States   <=50K  \n",
       "4            0            0            40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the Data Set\n",
    "df = pd.read_csv(\"clusteringdata.csv\")\n",
    "#print th first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any space in the names of the columns\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the duplicate Rows\n",
    "df = df.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                0\n",
       "WorkClass          0\n",
       "Fnlwght            0\n",
       "Education          0\n",
       "EducationNumber    0\n",
       "MaritalStatus      0\n",
       "Occupation         0\n",
       "Relationship       0\n",
       "Race               0\n",
       "Sex                0\n",
       "CapitalGain        0\n",
       "CapitalLoss        0\n",
       "HoursPerWeek       0\n",
       "NativeCountry      0\n",
       "Class              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in the columns\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4579 entries, 0 to 4999\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Age              4579 non-null   int64 \n",
      " 1   WorkClass        4579 non-null   object\n",
      " 2   Fnlwght          4579 non-null   int64 \n",
      " 3   Education        4579 non-null   object\n",
      " 4   EducationNumber  4579 non-null   int64 \n",
      " 5   MaritalStatus    4579 non-null   object\n",
      " 6   Occupation       4579 non-null   object\n",
      " 7   Relationship     4579 non-null   object\n",
      " 8   Race             4579 non-null   object\n",
      " 9   Sex              4579 non-null   object\n",
      " 10  CapitalGain      4579 non-null   int64 \n",
      " 11  CapitalLoss      4579 non-null   int64 \n",
      " 12  HoursPerWeek     4579 non-null   int64 \n",
      " 13  NativeCountry    4579 non-null   object\n",
      " 14  Class            4579 non-null   object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 572.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# This Code will Count the occuring of the '?' in all the columns\n",
    "for i in df.columns:\n",
    "    t = df[i].value_counts()\n",
    "    index = list(t.index)\n",
    "    #print (\"The Value Counts of ? in\", i)\n",
    "    for i in index:\n",
    "        temp = 0\n",
    "        if i == ' ?':\n",
    "           # print (t[' ?'])\n",
    "            temp = 1\n",
    "            break\n",
    "    #if temp == 0:\n",
    "        #print (\"0\")\n",
    "# Dropping the rows which have '?' \n",
    "df = df[df.WorkClass != ' ?']\n",
    "df = df[df.Occupation != ' ?']\n",
    "df = df[df.NativeCountry != ' ?']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>WorkClass</th>\n",
       "      <th>Fnlwght</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationNumber</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>CapitalGain</th>\n",
       "      <th>CapitalLoss</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>NativeCountry</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  WorkClass  Fnlwght  Education  EducationNumber  MaritalStatus  \\\n",
       "0   39          5    77516          9               13              4   \n",
       "1   50          4    83311          9               13              2   \n",
       "2   38          2   215646         11                9              0   \n",
       "3   53          2   234721          1                7              2   \n",
       "4   28          2   338409          9               13              2   \n",
       "\n",
       "   Occupation  Relationship  Race  Sex  CapitalGain  CapitalLoss  \\\n",
       "0           0             1     4    1         2174            0   \n",
       "1           3             0     4    1            0            0   \n",
       "2           5             1     4    1            0            0   \n",
       "3           5             0     2    1            0            0   \n",
       "4           9             5     2    0            0            0   \n",
       "\n",
       "   HoursPerWeek  NativeCountry  Class  \n",
       "0            40             36      0  \n",
       "1            13             36      0  \n",
       "2            40             36      0  \n",
       "3            40             36      0  \n",
       "4            40              4      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'] = df['Class'].map({' <=50K':0, ' >50K':1})\n",
    "df['Class'].value_counts()\n",
    "# Changing the Categorical Values to Numerical values using the Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "features = list(df.select_dtypes(include=['object']).columns)\n",
    "le_feat = {}\n",
    "# using enumerator to keep a count of iterations.\n",
    "for i, feature in enumerate(features):\n",
    "    #to converting the labels(feature) into numeric form\n",
    "    le_feat[feature] = LabelEncoder() \n",
    "    #scale the training data and also learn the scaling parameters of that data\n",
    "    df[feature] = le_feat[feature].fit_transform(df[feature])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1-a: Determine “k” value from the elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will be using the elbow method to determine the optimal number of clusters for k-means clustering.\n",
    "\n",
    "We need some way to determine whether we are using the right number of clusters when using k-means clustering. One method to validate the number of clusters is the elbow method. \n",
    "\n",
    "The idea of the elbow method is to run k-means clustering on the dataset for a range of values of k (k will be from 1 to 10 in this task), and for each value of k calculate the sum of squared errors (SSE). Then, plot a line chart of the SSE for each value of k. If the line chart looks like an arm, then the \"elbow\" on the arm is the value of k that is the best. The idea is that we want a small SSE, but that the SSE tends to decrease toward 0 as we increase k (the SSE is 0 when k is equal to the number of data points in the dataset, because then each data point is a cluster, and there is no error between it and the center of its cluster). So our goal is to choose a small value of k that still has a low SSE, and the elbow usually represents where we start to have diminishing returns by increasing k.\n",
    "\n",
    "For this task, you need to perform the elbow method for k from 1 to 10 and plot a line chart of the SSE for each value of k, and determine the best k (the number of clusters). Note that you need to use the whole dataset in this task and you need to print your decision for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Squared Errors\n",
    "SSE = {} \n",
    "for k in range(1, 11):     \n",
    "    kmeans = KMeans(n_clusters=k, random_state=1)     \n",
    "    kmeans.fit(df)     \n",
    "    SSE[k] = kmeans.inertia_ \n",
    "# sum of squared distances to closest cluster cente\n",
    "# Plot SSE for each *k* \n",
    "plt.title('The Elbow Method') \n",
    "plt.xlabel('k'); \n",
    "plt.ylabel('SSE') \n",
    "#plt.plot(list(SSE.keys()),list(SSE.values()), color='black', marker=(5,0), markerfacecolor='black', markersize=10)\n",
    "print(\"The best value for k in the\")\n",
    "sns.pointplot(x=list(SSE.keys()), y=list(SSE.values())) \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1-b: Visualization for K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will be performing k-means clustering for k=2 and visualize the predicted training samples and actual training samples on scatter plots. Use 70% of the dataset for training and 30% of the dataset for testing. Perform kmeans for clustering samples in your training set. \n",
    "\n",
    "Use two subplots for visualizing the predicted training samples and actual training samples on two scatter plots.\n",
    "\n",
    "Since your dataset has multiple features(dimensions), you won't be able to plot your data on a scatter plot. Thus, you’re going to visualize your data with the help of one of the Dimensionality Reduction techniques, namely Principal Component Analysis (PCA). The idea in PCA is to find a linear combination of the two variables that contains most of the information. This new variable or “principal component” can replace the two original variables. You can easily apply PCA to your data with the help of scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 1-b-1: Split the dataset 70% for training and 30% for testing\n",
    "C1 = df.drop(columns = ['Class'])\n",
    "C2 = df['Class']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(C1, C2, test_size = 0.3,random_state = 100)\n",
    "###################end code for Task 1-b-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################begin code for Task 1-b-2: Visualize the predicted training labels vs actual training labels\n",
    "\n",
    "# Import PCA\n",
    "\n",
    "# Create the KMeans model\n",
    "kmeans = KMeans(n_clusters= 2)\n",
    "# fit our model using our training data.\n",
    "kmeans.fit(X_train, Y_train)\n",
    "\n",
    "# Compute cluster centers and predict cluster index for each sample \n",
    "clusters = kmeans.fit_predict(X_train)\n",
    "\n",
    "# Model and fit the data to the PCA model\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Visualize the predicted training labels vs actual training labels. \n",
    "# scatter(x, y, your_data)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# Adjust layout\n",
    "fig.suptitle('Predicted Versus Training Labels', fontsize=14, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.9)\n",
    "\n",
    "# Add scatterplots to the subplots \n",
    "x = X_train_pca[:, 0]\n",
    "y = X_train_pca[:, 1]\n",
    "s=ax[0].scatter(x, y, c=clusters)\n",
    "ax[0].set_title('Predicted Training Labels')\n",
    "ax[1].scatter(x, y, c=Y_train)\n",
    "ax[1].set_title('Actual Training Labels')\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel='First PCA component', ylabel='Second PCA component')\n",
    "    legend1 = a.legend(*s.legend_elements(),\n",
    "                    loc=\"upper right\", title=\"Classes\")\n",
    "    a.add_artist(legend1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "###################end code for Task 1-b-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you need to visualize the predicted testing labels versus actual testing labels. Use the trained model in previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 1-b-3: Visualize the predicted testing labels vs actual testing labels\n",
    "# Create the KMeans model\n",
    "kmeans_val = KMeans(n_clusters= 2)\n",
    "\n",
    "# predict cluster index for each sample \n",
    "cluster_index = kmeans_val.fit_predict(X_test)\n",
    "\n",
    "# Model and fit the data to the PCA model\n",
    "pca = PCA()\n",
    "#X_train_pca = pca.fit_transform(X_test)\n",
    "X_train_pca = PCA(n_components=2).fit_transform(X_test)\n",
    "\n",
    "# Visualize the predicted testing labels vs actual testing labels. \n",
    "img, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# Adjust layout\n",
    "fig.suptitle('Predicted Versus Testing Labels', fontsize=14, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.9)\n",
    "\n",
    "# Add scatterplots to the subplots \n",
    "x = X_train_pca[:, 0]\n",
    "y = X_train_pca[:, 1]\n",
    "s = ax[0].scatter(x, y, c=cluster_index)\n",
    "ax[0].set_title('Predicted Testing Labels')\n",
    "ax[1].scatter(x, y, c=Y_test)\n",
    "ax[1].set_title('Actual Testing Labels')\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel='First PCA component', ylabel='Second PCA component')\n",
    "    legend1 = a.legend(*s.legend_elements(),loc=\"upper right\", title=\"Classes\")\n",
    "    a.add_artist(legend1)\n",
    "plt.show()\n",
    "\n",
    "###################end code for Task 1-b-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you need to provide the evaluation of your clustering model. Print out a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 1-b-4: Print out a confusion matrix\n",
    "\n",
    "Y_prediction = kmeans.predict(X_test)\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(Y_test,Y_prediction),'\\n')\n",
    "print(\"Classification Report: \\n\",classification_report(Y_test,Y_prediction))\n",
    "\n",
    "###################end code for Task 1-b-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Hierarchical Agglomerative  Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2-a: Find the best Hierarchical Agglomerative Clustering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will be performing Hierarchical Agglomerative clustering with different linkage methods (complete and average) and different similarity measures (cosine, euclidean, and manhattan) in order to find the best pair of linkage method and similarity measure. Use F1 score for evaluation and take n_clusters = 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 2-a: Print out a confusion matrix\n",
    "\n",
    "## Calculate pairwise distance matrix for X_train\n",
    "pdm_train = pairwise_distances(X_train)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## complete linkage + cosine\n",
    "complete_cosine = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage=\"complete\")\n",
    "prediction1 = complete_cosine.fit_predict(X_train)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## complete linkage + euclidean\n",
    "complete_euclidean = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage=\"complete\")\n",
    "prediction2 = complete_euclidean.fit_predict(X_train)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## complete linkage + manhattan\n",
    "complete_manhattan = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage=\"complete\")\n",
    "prediction3 = complete_manhattan.fit_predict(X_train)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## average linkage + cosine\n",
    "average_cosine = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage=\"average\")\n",
    "prediction4 = average_cosine.fit_predict(X_train)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## average linkage + euclidean\n",
    "average_euclidean = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage=\"average\")\n",
    "prediction5 = average_euclidean.fit_predict(X_train)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## average linkage + manhattan\n",
    "average_manhattan = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage=\"average\")\n",
    "prediction6 = average_manhattan.fit_predict(X_train)\n",
    "\n",
    "print(\"F1-score for complete linkage + cosine\",f1_score(Y_train, prediction1))\n",
    "print(\"F1-score for complete linkage + euclidean\", f1_score(Y_train, prediction2))\n",
    "print(\"F1-score for complete linkage + manhattan\",f1_score(Y_train, prediction3))\n",
    "print(\"F1-score for average linkage + cosine\", f1_score(Y_train, prediction4))\n",
    "print(\"F1-score for average linkage + euclidean\", f1_score(Y_train, prediction5))\n",
    "print(\"F1-score for average linkage + manhattan\", f1_score(Y_train, prediction6))\n",
    "\n",
    "###################end code for Task 2-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2-b:  Visualization for Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best performed model from the previous step and use that model for visualizing the predicted training samples and actual training samples on scatter plots. Use PCA model for visualizing your data (use X_train_pca from Task 1-b-2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 2-b: Visualize the predicted training labels vs actual training labels\n",
    "\n",
    "# Model and fit the data to the PCA model\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Visualize the predicted training labels vs actual training labels. \n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "img.suptitle('Predicted Versus Training Labels', fontsize=14, fontweight='bold')\n",
    "img.subplots_adjust(top=0.9)\n",
    "\n",
    "# Add scatterplots to the subplots \n",
    "x = X_train_pca[:, 0]\n",
    "y = X_train_pca[:, 1]\n",
    "s=ax[0].scatter(x, y, c=prediction2)\n",
    "ax[0].set_title('Predicted Training Labels')\n",
    "ax[1].scatter(x, y, c=Y_train)\n",
    "ax[1].set_title('Actual Training Labels')\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel='First PCA component', ylabel='Second PCA component')\n",
    "    legend1 = a.legend(*s.legend_elements(),\n",
    "                    loc=\"upper right\", title=\"Classes\")\n",
    "    a.add_artist(legend1)\n",
    "plt.show()\n",
    "\n",
    "###################end code for Task 2-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3:  Compare K-Means Clustering and Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3-a: Visualize Clusters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, use whole dataset for training k-means cluster and hierarchical agglomerative clustering. Use the best model for agglomerative clustering. Visualize the predicted labels from k-means clustering and agglomerative clustering versus actual labels. Basically, you need to plot three scatter plots as subplots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## complete linkage + cosine\n",
    "X = df[df.columns[:-1]]\n",
    "Y = df[df.columns[-1]]\n",
    "complete_cosine = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage=\"complete\")\n",
    "pred1 = complete_cosine.fit_predict(X)\n",
    "\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## complete linkage + euclidean\n",
    "complete_euclidean = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage=\"complete\")\n",
    "pred2 = complete_euclidean.fit_predict(X)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## complete linkage + manhattan\n",
    "complete_manhattan = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage=\"complete\")\n",
    "pred3 = complete_manhattan.fit_predict(X)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## average linkage + cosine\n",
    "average_cosine = AgglomerativeClustering(n_clusters=2, affinity='cosine', linkage=\"average\")\n",
    "pred4 = average_cosine.fit_predict(X)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## average linkage + euclidean\n",
    "average_euclidean = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage=\"average\")\n",
    "pred5 = average_euclidean.fit_predict(X)\n",
    "\n",
    "## Model and fit the training data to the AgglomerativeClustering model\n",
    "## average linkage + manhattan\n",
    "average_manhattan = AgglomerativeClustering(n_clusters=2, affinity='manhattan', linkage=\"average\")\n",
    "pred6 = average_manhattan.fit_predict(X)\n",
    "\n",
    "print(\"F1-score for complete linkage + cosine\",f1_score(Y, pred1))\n",
    "print(\"F1-score for complete linkage + euclidean\", f1_score(Y, pred2))\n",
    "print(\"F1-score for complete linkage + manhattan\",f1_score(Y, pred3))\n",
    "print(\"F1-score for average linkage + cosine\", f1_score(Y, pred4))\n",
    "print(\"F1-score for average linkage + euclidean\", f1_score(Y, pred5))\n",
    "print(\"F1-score for average linkage + manhattan\", f1_score(Y, pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 3-a: Visualize the predicted training labels vs actual training labels\n",
    "\n",
    "### Kmeans Clustering\n",
    "# Model and fit the data to the Kmeans (use fit_predict : Performs clustering on X and returns cluster labels.)\n",
    "X = df.drop(columns = ['Class'])\n",
    "Y = df['Class']\n",
    "kmeans = KMeans(n_clusters=2,random_state=100)\n",
    "kmeans_prediction = kmeans.fit_predict(X)\n",
    "\n",
    "### Agglomerative Clustering\n",
    "# Calculate pairwise distance matrix for X\n",
    "pdm_train = pairwise_distances(X)\n",
    "# print(pdm_train)\n",
    "\n",
    "# Model and fit the data to the Agglomerative (use fit_predict : Performs clustering on X and returns cluster labels.)\n",
    "Agg_clustering = AgglomerativeClustering(n_clusters=2)\n",
    "Agg_prediction = Agg_clustering.fit_predict(X)\n",
    "\n",
    "#  Model and fit the data to the PCA model\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Visualize the predicted Kmeans labels versus  the predicted Agglomerative labels versus Actual labels. \n",
    "# scatter(x, y, your_data)\n",
    "fig1, ax = plt.subplots(1, 2,figsize=(15, 6))\n",
    "fig, axs = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "fig1.suptitle('predicted Kmeans labels versus  the predicted Agglomerative labels versus Actual labels', fontsize=14, fontweight='bold')\n",
    "fig1.subplots_adjust(top=0.9)\n",
    "\n",
    "# Add scatterplots to the subplots \n",
    "x = X_pca[:, 0]\n",
    "y = X_pca[:, 1]\n",
    "s=ax[0].scatter(x, y, c=kmeans_prediction)\n",
    "ax[0].set_title('Predicted Kmeans labels')\n",
    "ax[1].scatter(x, y, c=pred4)\n",
    "ax[1].set_title('Predicted Agglomerative labels')\n",
    "s=axs.scatter(x, y, c=Y)\n",
    "axs.set_title('Actual Training Labels')\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel='First PCA component', ylabel='Second PCA component')\n",
    "    legend1 = a.legend(*s.legend_elements(),\n",
    "                    loc=\"upper right\", title=\"Classes\")\n",
    "    a.add_artist(legend1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "###################end code for Task 3-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3-b: Compare K-Means Clustering &  Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out confusion matrices for kmeans and agglomerative clustering. Also, compare precision, recall, and F1-score for both model. Type your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 3-b\n",
    "Y_kmeans_pred = kmeans.predict(X)\n",
    "print(\"Kmeans:\\n Accuracy is:\", accuracy_score(Y,Y_kmeans_pred)*100,\"\\n\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(Y,Y_kmeans_pred),'\\n')\n",
    "print(\"Classification Report: \\n\",classification_report(Y,Y_kmeans_pred))\n",
    "\n",
    "Y_Agglemorative_pred = Agg_clustering.fit_predict(X)\n",
    "print(\"Agglomerative clustering: \\nAccuracy is:\", accuracy_score(Y,Y_Agglemorative_pred)*100,\"\\n\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(Y,Y_Agglemorative_pred),'\\n')\n",
    "print(\"Classification Report: \\n\",classification_report(Y,Y_Agglemorative_pred))\n",
    "###################end code for Task 3-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>[05 points] Follow the Rules</b> \n",
    "\n",
    "\n",
    "<b>[45 points] Task 1:</b>  \n",
    "\n",
    "    [15 points] Task 1-a: Determine “k” value from the elbow method\n",
    "\n",
    "    [30 points] Task 1-b: Visualization for K-Means Clustering\n",
    "\n",
    "        [05 points] Task 1-b-1: Split the dataset \n",
    "    \n",
    "        [10 points] Task 1-b-2: Visualize the predicted training vs actual training labels \n",
    "    \n",
    "        [10 points] Task 1-b-3: Visualize the predicted testing vs actual testing labels\n",
    "    \n",
    "        [05 points] Task 1-b-4: Print out a confusion matrix\n",
    "    \n",
    "\n",
    "\n",
    "<b>[50 points] Task 2:</b>  \n",
    "\n",
    "    [35 points] Task 2-a: Find the best Hierarchical Agglomerative Clustering Model\n",
    "\n",
    "    [15 points] Task 2-b: Visualization for Hierarchical Agglomerative Clustering\n",
    "\n",
    "\n",
    "\n",
    "<b>[20 points] Task 3 (BONUS):</b> \n",
    "\n",
    "    Task 3-a: 10 points\n",
    "\n",
    "    Task 3-b: 10 points"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
